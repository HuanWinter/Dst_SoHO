{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ import package\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import h5py\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from ipdb import set_trace as st\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import linecache as lc\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import io as sio\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from funs import SoHO_read, Read_solar_image, \\\n",
    "    dt2date, Prob_train\n",
    "\n",
    "\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Config ######################\n",
    "time_stamp = 'Data/time_data_19873_train_valid_test.h5'\n",
    "channels = ['MDI','EIT','LASCO'] # , ,'LASCO_diff','MDI_diff',\n",
    "\n",
    "dst_peak = -75\n",
    "delay = 24\n",
    "time_res = 2\n",
    "Peak_width = 5\n",
    "Peak_dis = 120\n",
    "F107_thres = [0, 500]\n",
    "SDO_flag = 1\n",
    "storm_idx = [15]\n",
    "var_idx = [0, 1, 2]\n",
    "batch = 64\n",
    "Resi_opt = 1000\n",
    "\n",
    "delay_range = 12*time_res\n",
    "delay_hour_clu = range(delay, delay+delay_range, time_res)\n",
    "SoHO_file = 'Res/Solar_data_19873.h5'\n",
    "Omni_data = 'Data/1999-2010.pkl'\n",
    "hmi_file = 'Data/hmi_halloween2021.h5'\n",
    "\n",
    "Res_name = 'Res/Dst_'+\\\n",
    "    str(delay)+'-'+\\\n",
    "    str(delay+delay_range) + '-'+\\\n",
    "    str(time_res) + '--'+\\\n",
    "    str(dst_peak)+'.h5'\n",
    "\n",
    "# filename_Y = 'Results/Bz_GSE_0-48.h5'\n",
    "callname = 'Res/params_'+\\\n",
    "    str(np.array(var_idx))+'_'+ \\\n",
    "    str(delay)+'-' +\\\n",
    "    str(delay+12*time_res) +'--'+\\\n",
    "    str(time_res)+'-' +\\\n",
    "    str(dst_peak)+'-'+\\\n",
    "    str(storm_idx[0])+'.pt'\n",
    "\n",
    "callname_opt = 'Res/params_opt_'+\\\n",
    "    str(np.array(var_idx))+'_'+ \\\n",
    "    str(delay)+'-' +\\\n",
    "    str(delay+12*time_res) +'--'+\\\n",
    "    str(time_res)+'-' +\\\n",
    "    str(dst_peak)+'-'+\\\n",
    "    str(storm_idx[0])+'.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value count     0/96441\n"
     ]
    }
   ],
   "source": [
    "################### global variables #################\n",
    "\n",
    "df = pd.read_pickle(Omni_data)\n",
    "omni_data = df['DST']\n",
    "omni_date = df.index\n",
    "\n",
    "# Fill missing values\n",
    "print(f'Missing value count \\\n",
    "    {omni_data.isna().sum()}/{len(omni_data)}')\n",
    "omni_data.interpolate(inplace=True)\n",
    "omni_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### SoHO data (X, run it once) ######################\n",
    "\n",
    "with h5py.File(time_stamp,'r') as f:\n",
    "    print(f.keys())\n",
    "    train_date = np.array(f['train_15645_dates'])\n",
    "    valid_date = np.array(f['valid_2301_dates'])\n",
    "    test_date = np.array(f['test_1927_dates'])\n",
    "    f.close()\n",
    "\n",
    "all_date = np.vstack([valid_date, train_date, test_date])\n",
    "X_all, Y_all = SoHO_read(channels, win_size=1)\n",
    "\n",
    "with h5py.File('Res/Solar_data_19873.h5', 'w') as f:\n",
    "\n",
    "    f.create_dataset('X', data=X_all)\n",
    "    # f.create_dataset('Y', data=Y_all)\n",
    "    f.create_dataset('date', data=all_date)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/19873 [00:00<02:27, 134.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value count     0/96441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19873/19873 [02:27<00:00, 134.63it/s]\n"
     ]
    }
   ],
   "source": [
    "###################### Dst data (Y, run it once) ######################\n",
    "\n",
    "with h5py.File(SoHO_file, 'r+') as f:\n",
    "\n",
    "    for v in ['Y']:\n",
    "        if v in f:\n",
    "            del f[v]\n",
    "    \n",
    "    all_date = np.array(f['date'])\n",
    "\n",
    "    out = np.zeros([len(all_date), delay_range//time_res])\n",
    "\n",
    "    for idx in tqdm(range(len(all_date))):\n",
    "        out[idx] = Read_solar_image(idx, omni_data, \n",
    "                                    omni_date, all_date,\n",
    "                                    time_res, delay_range, delay)\n",
    "\n",
    "    f.create_dataset('Y', data=out)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19873/19873 [00:00<00:00, 167779.25it/s]\n",
      "90it [00:00, 3020.84it/s]\n",
      "9it [00:00, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 1999-04-15 20:00:00/1999-04-22 08:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2000-02-10 07:00:00/2000-02-20 12:00:00\n",
      "start/end time 2000-04-14 19:00:00/2000-04-19 11:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:01, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2000-06-07 13:00:00/2000-06-14 01:00:00\n",
      "start/end time 2000-06-25 02:00:00/2000-07-01 09:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2000-08-09 05:00:00/2000-08-20 07:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:02, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2001-05-06 00:00:00/2001-05-17 18:00:00\n",
      "start/end time 2001-09-24 21:00:00/2001-10-08 08:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:02, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2001-09-24 21:00:00/2001-10-08 08:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:02, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2001-11-23 06:00:00/2001-12-01 14:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:03, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2002-03-22 15:00:00/2002-03-29 21:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:03, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2002-07-31 23:00:00/2002-08-08 03:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:04, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2003-08-16 18:00:00/2003-09-01 23:00:00\n",
      "start/end time 2003-10-24 02:00:00/2003-11-05 06:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:04, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2004-07-15 22:00:00/2004-07-21 18:00:00\n",
      "start/end time 2004-07-23 11:00:00/2004-08-07 18:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:05, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2005-05-06 21:00:00/2005-05-16 02:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [00:05, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2005-07-09 11:00:00/2005-07-17 18:00:00\n",
      "start/end time 2005-08-23 08:00:00/2005-09-01 03:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:06, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2006-04-07 10:00:00/2006-04-14 02:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:06, 14.38it/s]\n",
      " 10%|▉         | 2/21 [00:00<00:01, 17.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start/end time 2008-03-07 12:00:00/2008-03-20 10:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 16.84it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_ex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5a01460803bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mdst_peak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_date\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_ex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_ex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_ex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_ex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y_ex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_ex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_ex' is not defined"
     ]
    }
   ],
   "source": [
    "##########dst storm time selection(run it once) ###################\n",
    "\n",
    "dates = []\n",
    "sample_storm = []\n",
    "n = 1\n",
    "\n",
    "with h5py.File(SoHO_file, 'r') as f:\n",
    "    X = np.array(f['X'])\n",
    "    Y = np.array(f['Y'])\n",
    "    all_date = np.array(f['date'])\n",
    "    f.close()\n",
    "\n",
    "if SDO_flag:\n",
    "    with h5py.File(hmi_file, 'r') as f:\n",
    "\n",
    "        X_ex = np.array(f['data'])\n",
    "        Y_reg_ex = np.array(f['y'])\n",
    "        Y_ex = np.zeros(Y_reg_ex.shape)\n",
    "        Y_ex[Y_reg_ex<dst_peak] = 1\n",
    "        date_ex = np.array(f['date'])\n",
    "        f.close()\n",
    "\n",
    "for ind in tqdm(range(len(all_date))):\n",
    "    date = dt2date(all_date[ind], time_res)\n",
    "    dates.append(date)\n",
    "\n",
    "peaks, _ = find_peaks(omni_data*-1,\n",
    "                    # height=np.abs(args.Dst_sel),\n",
    "                    distance=Peak_dis,\n",
    "                    width=Peak_width)\n",
    "idx = np.where(omni_data[peaks] <= dst_peak)[0]\n",
    "\n",
    "idx_clu = np.zeros([len(idx), 2])\n",
    "\n",
    "for i, idx_t in tqdm(enumerate(idx)):\n",
    "\n",
    "    # print('peak {}:'.format(i), Omni_date[peaks[idx_t]])\n",
    "\n",
    "    idx_clu[i, 0] = np.where(\n",
    "        omni_data[:peaks[idx_t]] >= 0)[0][-1]-delay_range\n",
    "    idx_clu[i, 1] = np.where(\n",
    "        omni_data[peaks[idx_t]:] >= 0)[0][0]+delay_range+peaks[idx_t]\n",
    "\n",
    "idx_clu = idx_clu.astype(int)\n",
    "\n",
    "for i, idx in tqdm(enumerate(idx_clu)):\n",
    "    date_end = omni_date[int(idx[1])]\n",
    "    date_beg = omni_date[int(idx[0])]\n",
    "\n",
    "    index_image = [j for j in range(len(dates)) if\n",
    "                    ((date_beg <= dates[j]+dt.timedelta(hours=delay))\n",
    "                    & (date_end >= dates[j]+dt.timedelta(hours=delay)))\n",
    "                    ]\n",
    "\n",
    "    if len(index_image) >= 28:\n",
    "        gap = np.zeros(len(index_image) - 1)\n",
    "        for k, idx_image in enumerate(index_image[:-1]):\n",
    "            gap_t = dates[index_image[k+1]] - dates[index_image[k]]\n",
    "            gap[k] = gap_t.seconds//3600\n",
    "\n",
    "        if ((gap > time_res).sum() <= 5) & (len(index_image) > 48):\n",
    "\n",
    "            sample_storm.append(index_image)\n",
    "            # print('size of {}th storm should be {}/{}'\\\n",
    "            #     .format(n, (idx[1]-idx[0])//time_res, \n",
    "            #     len(index_image)))\n",
    "            \n",
    "            date_plot = [dates[j] for j in index_image]\n",
    "            plt.plot(date_plot, \\\n",
    "                Y[index_image, 0], \n",
    "                'r.')\n",
    "            plt.xticks(rotation='vertical')\n",
    "\n",
    "            plt.savefig('Figs/sample_'+str(n)+'.jpg', dpi=300)\n",
    "            plt.close()\n",
    "            print('start/end time {}/{}'.format(date_beg, date_end))\n",
    "            # print('end time', date_end)\n",
    "            \n",
    "            n += 1\n",
    "\n",
    "            if n == 51:\n",
    "                break\n",
    "\n",
    "with h5py.File(Res_name, 'r+') as f:\n",
    "\n",
    "    for v in ['X_ex', 'Y_ex', 'Y_reg_ex', \\\n",
    "        'time_ex', 'storm_num']:\n",
    "        if v in f:\n",
    "            del f[v]\n",
    "    # import ipdb;ipdb.set_trace()\n",
    "    for i in tqdm(range(len(sample_storm))):\n",
    "\n",
    "        idx = sample_storm[i]\n",
    "        for v in ['X_'+str(i), 'Y_'+str(i),\n",
    "                    'Y_reg_'+str(i), 'time_'+str(i)]:\n",
    "            if v in f:\n",
    "                del f[v]\n",
    "\n",
    "        f.create_dataset('X_'+str(i), data=X[idx])\n",
    "        f.create_dataset('Y_reg_'+str(i), data=Y[idx])\n",
    "        f.create_dataset('Y_'+str(i), data=Y[idx]<dst_peak)\n",
    "        f.create_dataset('time_'+str(i), data=all_date[idx])\n",
    "    f.create_dataset('X_ex', data=X_ex)\n",
    "    f.create_dataset('time_ex', data=date_ex)\n",
    "    f.create_dataset('Y_ex', data=Y_ex)\n",
    "    f.create_dataset('Y_reg_ex', data=Y_reg_ex)\n",
    "    f.create_dataset('storm_num', data=len(sample_storm))\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd40fc67c7a1d91df4ca13919301e6ab29b05d53552f9fb4893f522d4c0bcec3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('pwork')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
